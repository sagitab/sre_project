# SRE Home Test Assignment

This project demonstrates a **real-time Change Data Capture (CDC) pipeline** that streams database events from a distributed **TiDB** cluster into **Apache Kafka** using **TiCDC**, with a **Node.js consumer** processing the live event stream.

The project highlights **automation, container orchestration, and distributed systems concepts**, making it suitable for DevOps and Data Engineering portfolios.

---

## ğŸ”¹ Key Features

### ğŸ—„ Distributed NewSQL Database
- Uses **TiDB** (TiDB, PD, and TiKV components)
- High availability and horizontal scalability
- Strong consistency with Raft-based replication

### ğŸ”„ Real-Time CDC Pipeline
- **TiCDC** captures incremental data changes
- Events are streamed into **Kafka**
- Uses **Canal-JSON** protocol for compatibility

### ğŸ³ Dockerized Infrastructure
- Entire stack orchestrated with **Docker Compose**
- Custom networking between TiDB, Kafka, and consumer
- Health checks and dependency management

### âš™ Automated Startup Sequencing
- Includes a `start.sh` automation script
- Handles:
  - Raft leader election timing
  - PD metadata synchronization
  - TiCDC changefeed creation
- Built-in **120s grace period** to ensure cluster readiness

---

## ğŸš€ Getting Started

### 1ï¸âƒ£ Prerequisites
- Docker  
- Docker Compose  
- Git Bash (recommended for Windows users)

---

### 2ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/sagitab/sre_project.git
cd sre_project
```

---

## start the project

```bash
chmod +x start.sh
./start.sh
```
## ğŸ“‚ Project Structure

```text
.
â”œâ”€â”€ app/                     # Main application logic (producer / core services)
â”œâ”€â”€ consumer/                # Node.js Kafka consumer (kafkajs)
â”œâ”€â”€ db_script/               # SQL scripts for TiDB schema and test data
â”œâ”€â”€ docker-compose.yml       # Orchestrates TiDB, Kafka, TiCDC, and services
â”œâ”€â”€ prometheus.yml           # Prometheus monitoring configuration (optional need to set up manually)
â”œâ”€â”€ start.sh                 # Automated startup & CDC initialization script
â”œâ”€â”€ README.md                # Project documentation
â”œâ”€â”€ .gitignore               # Ignored files and artifacts
â”œâ”€â”€ cmd.txt                  # Local command notes (optional, ignore)
â”œâ”€â”€ docker-compose.yml.txt   # Backup / reference compose file (ignore)
â”œâ”€â”€ logs.txt                 # Local logs output (ignore)
```
## ğŸ—„ Connect to TiDB Database

Once the pipeline is running, you can connect to the TiDB cluster locally using the MySQL client:

```bash
#connect to server
mysql -h 127.0.0.1 -P 4000 -u root
#select database
use app_db;
#update user name
update users set username = "sagi" where id = 1;
#check the user updated
select * from users;
# now you can see the changes in the consumer logs
```
## CleanUP
```bash
docker-compose down -v
```
